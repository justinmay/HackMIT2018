{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA_Crossing_01-D.xml\n",
      "AA_Easy_01-D.xml\n",
      "AA_Easy_02-D.xml\n",
      "AA_Easy_Entrance-D.xml\n",
      "Munich01-D.xml\n",
      "AA_Walking_01-D.xml\n",
      "RaR_Snack_Zone_01-D.xml\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "\n",
    "xml = ['AA_Crossing_01-D.xml', 'AA_Easy_01-D.xml', 'AA_Easy_02-D.xml', 'AA_Easy_Entrance-D.xml', 'Munich01-D.xml', 'AA_Walking_01-D.xml', 'RaR_Snack_Zone_01-D.xml']\n",
    "\n",
    "for file_name in xml:\n",
    "    print(file_name)\n",
    "    tree = ET.parse(\"./Data_Sets/IPF_Detections/\" + file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for frame in root:\n",
    "        file = frame.attrib['file'].split('/')\n",
    "        file = \"./Data_Sets/x_train/\" + file[-1]\n",
    "        for objectlist in frame:\n",
    "            for object in objectlist:\n",
    "                label = []\n",
    "                label.append(file)\n",
    "                label.append(object[0].attrib['xc'])\n",
    "                label.append(object[0].attrib['yc'])\n",
    "                label.append(object[0].attrib['w'])\n",
    "                label.append(object[0].attrib['h'])\n",
    "                train_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA_Crossing_02-D.xml\n",
      "AA_Entrance_01-D.xml\n",
      "AA_Walking_02-D.xml\n",
      "AA_Easy_Entrance-D.xml\n",
      "Munich02-D.xml\n",
      "RaR_Snack_Zone_02-D.xml\n",
      "RaR_Snack_Zone_04-D.xml\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "\n",
    "xml = ['AA_Crossing_02-D.xml', 'AA_Entrance_01-D.xml', 'AA_Walking_02-D.xml', 'AA_Easy_Entrance-D.xml', 'Munich02-D.xml', 'RaR_Snack_Zone_02-D.xml', 'RaR_Snack_Zone_04-D.xml']\n",
    "\n",
    "for file_name in xml:\n",
    "    print(file_name)\n",
    "    tree = ET.parse(\"./Data_Sets/IPF_Detections/\" + file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for frame in root:\n",
    "        file = frame.attrib['file'].split('/')\n",
    "        file = \"./Data_Sets/x_test/\" + file[-1]\n",
    "        for objectlist in frame:\n",
    "            for object in objectlist:\n",
    "                label = []\n",
    "                label.append(file)\n",
    "                label.append(object[0].attrib['xc'])\n",
    "                label.append(object[0].attrib['yc'])\n",
    "                label.append(object[0].attrib['w'])\n",
    "                label.append(object[0].attrib['h'])\n",
    "                test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = (0, 0, 409, 387)\n",
    "x_train = []\n",
    "y_train = []\n",
    "# i = 1\n",
    "for file in train_labels:\n",
    "    filename = file[0].split('/')[-1]\n",
    "    if filename.endswith(\".png\"):\n",
    "        try:\n",
    "            img = load_img(\"./Data_Sets/x_train/\" + filename)\n",
    "        except:\n",
    "            continue\n",
    "        cropped_img = img.crop(area)\n",
    "        img_array = img_to_array(cropped_img) / 255\n",
    "        x_train.append(img_array)\n",
    "        y_train.append(file[1:])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = (0, 0, 409, 387)\n",
    "x_test = []\n",
    "y_test = []\n",
    "# i = 1\n",
    "for file in test_labels:\n",
    "    filename = file[0].split('/')[-1]\n",
    "    if filename.endswith(\".png\"):\n",
    "        try:\n",
    "            img = load_img(\"./Data_Sets/x_test/\" + filename)\n",
    "        except:\n",
    "            continue\n",
    "        cropped_img = img.crop(area)\n",
    "        img_array = img_to_array(cropped_img) / 255\n",
    "        x_test.append(img_array)\n",
    "        y_test.append(file[1:])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add first convolutional layer - output:(32x32x32)\n",
    "# model.add(Conv2D(input_shape=(387, 409, 3), data_format='channels_last',\n",
    "#                 filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                 padding='same', kernel_initializer='he_uniform'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Add max-pooling layer (16x16x32)\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same',\n",
    "#                        data_format='channels_last'))\n",
    "\n",
    "# # Add second convolutional layer (14x14x64)\n",
    "# model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                  padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Add max-pooling layer (6x6x128)\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same',\n",
    "#                        data_format='channels_last'))\n",
    "\n",
    "# # Add third convolutional layer (12x12x128)\n",
    "# model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                  padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Add max-pooling layer (6x6x128)\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same',\n",
    "#                        data_format='channels_last'))\n",
    "\n",
    "\n",
    "# #Add up-sampling layer\n",
    "# model.add(UpSampling2D(size=(2, 2), data_format=None))\n",
    "\n",
    "# # Add third convolutional layer (12x12x128)\n",
    "# model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                  padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# #Add up-sampling layer\n",
    "# model.add(UpSampling2D(size=(2, 2), data_format=None))\n",
    "\n",
    "\n",
    "# # Add second convolutional layer (14x14x64)\n",
    "# model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                  padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# #Add up-sampling layer\n",
    "# model.add(UpSampling2D(size=(2, 2), data_format=None))\n",
    "\n",
    "# # Add second convolutional layer (14x14x64)\n",
    "# model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(1,1),\n",
    "#                  padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Add second convolutional layer (14x14x64)\n",
    "# model.add(Conv2D(filters=3, kernel_size=(8,1), strides=(1,1),\n",
    "#                  padding='valid'))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(387,409,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4, activation='linear')(x) #minor edit\n",
    "new_model = Model(input=model.input, output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model\n",
    "new_model.fit(x_train, y_train, epochs=25, batch_size=128,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[NEEDED] method to draw box around image given prediction coords\n",
    "bbox = model.predict(x_test)\n",
    "array_to_img(reconstructed_imgs(bbox) * 255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
